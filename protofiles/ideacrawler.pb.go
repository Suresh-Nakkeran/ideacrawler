// Code generated by protoc-gen-go. DO NOT EDIT.
// source: ideacrawler.proto

package protofiles

import (
	context "context"
	fmt "fmt"
	proto "github.com/golang/protobuf/proto"
	empty "github.com/golang/protobuf/ptypes/empty"
	grpc "google.golang.org/grpc"
	math "math"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package

type PageReqType int32

const (
	PageReqType_GET PageReqType = 0
	// Sends a HEAD request to first identify page is text/html before downloading
	// If we are unsure link will send back large gzip file, etc. which we want to
	// avoid.
	PageReqType_HEAD      PageReqType = 1
	PageReqType_BUILTINJS PageReqType = 2
	PageReqType_JSCRIPT   PageReqType = 3
)

var PageReqType_name = map[int32]string{
	0: "GET",
	1: "HEAD",
	2: "BUILTINJS",
	3: "JSCRIPT",
}

var PageReqType_value = map[string]int32{
	"GET":       0,
	"HEAD":      1,
	"BUILTINJS": 2,
	"JSCRIPT":   3,
}

func (x PageReqType) String() string {
	return proto.EnumName(PageReqType_name, int32(x))
}

func (PageReqType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_f7828dc51d79295c, []int{0}
}

type WorkerID struct {
	ID                   string   `protobuf:"bytes,1,opt,name=ID,json=iD,proto3" json:"ID,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *WorkerID) Reset()         { *m = WorkerID{} }
func (m *WorkerID) String() string { return proto.CompactTextString(m) }
func (*WorkerID) ProtoMessage()    {}
func (*WorkerID) Descriptor() ([]byte, []int) {
	return fileDescriptor_f7828dc51d79295c, []int{0}
}

func (m *WorkerID) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_WorkerID.Unmarshal(m, b)
}
func (m *WorkerID) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_WorkerID.Marshal(b, m, deterministic)
}
func (m *WorkerID) XXX_Merge(src proto.Message) {
	xxx_messageInfo_WorkerID.Merge(m, src)
}
func (m *WorkerID) XXX_Size() int {
	return xxx_messageInfo_WorkerID.Size(m)
}
func (m *WorkerID) XXX_DiscardUnknown() {
	xxx_messageInfo_WorkerID.DiscardUnknown(m)
}

var xxx_messageInfo_WorkerID proto.InternalMessageInfo

func (m *WorkerID) GetID() string {
	if m != nil {
		return m.ID
	}
	return ""
}

type Status struct {
	Success              bool     `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	Error                string   `protobuf:"bytes,2,opt,name=error,proto3" json:"error,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *Status) Reset()         { *m = Status{} }
func (m *Status) String() string { return proto.CompactTextString(m) }
func (*Status) ProtoMessage()    {}
func (*Status) Descriptor() ([]byte, []int) {
	return fileDescriptor_f7828dc51d79295c, []int{1}
}

func (m *Status) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_Status.Unmarshal(m, b)
}
func (m *Status) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_Status.Marshal(b, m, deterministic)
}
func (m *Status) XXX_Merge(src proto.Message) {
	xxx_messageInfo_Status.Merge(m, src)
}
func (m *Status) XXX_Size() int {
	return xxx_messageInfo_Status.Size(m)
}
func (m *Status) XXX_DiscardUnknown() {
	xxx_messageInfo_Status.DiscardUnknown(m)
}

var xxx_messageInfo_Status proto.InternalMessageInfo

func (m *Status) GetSuccess() bool {
	if m != nil {
		return m.Success
	}
	return false
}

func (m *Status) GetError() string {
	if m != nil {
		return m.Error
	}
	return ""
}

type KVP struct {
	Key                  string   `protobuf:"bytes,1,opt,name=key,proto3" json:"key,omitempty"`
	Value                string   `protobuf:"bytes,2,opt,name=value,proto3" json:"value,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *KVP) Reset()         { *m = KVP{} }
func (m *KVP) String() string { return proto.CompactTextString(m) }
func (*KVP) ProtoMessage()    {}
func (*KVP) Descriptor() ([]byte, []int) {
	return fileDescriptor_f7828dc51d79295c, []int{2}
}

func (m *KVP) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KVP.Unmarshal(m, b)
}
func (m *KVP) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KVP.Marshal(b, m, deterministic)
}
func (m *KVP) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KVP.Merge(m, src)
}
func (m *KVP) XXX_Size() int {
	return xxx_messageInfo_KVP.Size(m)
}
func (m *KVP) XXX_DiscardUnknown() {
	xxx_messageInfo_KVP.DiscardUnknown(m)
}

var xxx_messageInfo_KVP proto.InternalMessageInfo

func (m *KVP) GetKey() string {
	if m != nil {
		return m.Key
	}
	return ""
}

func (m *KVP) GetValue() string {
	if m != nil {
		return m.Value
	}
	return ""
}

type DomainOpt struct {
	SeedUrl string `protobuf:"bytes,1,opt,name=seedUrl,proto3" json:"seedUrl,omitempty"`
	// crawl delay in seconds
	MinDelay int32 `protobuf:"varint,2,opt,name=minDelay,proto3" json:"minDelay,omitempty"`
	MaxDelay int32 `protobuf:"varint,3,opt,name=maxDelay,proto3" json:"maxDelay,omitempty"`
	// don't follow any pages,  just send back responses for the received URLs.
	NoFollow bool `protobuf:"varint,4,opt,name=noFollow,proto3" json:"noFollow,omitempty"`
	// only pages matching reqUrlRegexp will be shipped back to the client.
	// only matching pages will be saved to s3 as well.
	CallbackUrlRegexp string `protobuf:"bytes,5,opt,name=callbackUrlRegexp,proto3" json:"callbackUrlRegexp,omitempty"`
	// only pages matching followUrlRegexp will be followed and sublinks added to fetcher.
	FollowUrlRegexp       string `protobuf:"bytes,6,opt,name=followUrlRegexp,proto3" json:"followUrlRegexp,omitempty"`
	MaxConcurrentRequests int32  `protobuf:"varint,7,opt,name=maxConcurrentRequests,proto3" json:"maxConcurrentRequests,omitempty"`
	//TODO
	Useragent string `protobuf:"bytes,8,opt,name=useragent,proto3" json:"useragent,omitempty"`
	Impolite  bool   `protobuf:"varint,9,opt,name=impolite,proto3" json:"impolite,omitempty"`
	//TODO
	Depth          int32 `protobuf:"varint,10,opt,name=depth,proto3" json:"depth,omitempty"`
	ThreadsPerSite int64 `protobuf:"varint,11,opt,name=ThreadsPerSite,json=threadsPerSite,proto3" json:"ThreadsPerSite,omitempty"`
	// Callback check order -
	//   (1) - callbackUrlRegexp
	//   (2) - callbackXpathMatch
	//   (3) - callbackXpathRegexp
	//  Any one has to match.
	// provide multiple xpaths as keys and expected values as value.  Pages are
	// sent back to client only if all values are found in page.
	CallbackXpathMatch  []*KVP `protobuf:"bytes,14,rep,name=callbackXpathMatch,proto3" json:"callbackXpathMatch,omitempty"`
	CallbackXpathRegexp []*KVP `protobuf:"bytes,15,rep,name=callbackXpathRegexp,proto3" json:"callbackXpathRegexp,omitempty"`
	//  in seconds, it is the time to wait for a new
	// page, before stopping the job; affects workerIdleTTL of fetchbot.
	// min value is 600, it is also default.
	MaxIdleTime        int64    `protobuf:"varint,16,opt,name=maxIdleTime,proto3" json:"maxIdleTime,omitempty"`
	FollowOtherDomains bool     `protobuf:"varint,17,opt,name=followOtherDomains,proto3" json:"followOtherDomains,omitempty"`
	KeepDomains        []string `protobuf:"bytes,18,rep,name=keepDomains,proto3" json:"keepDomains,omitempty"`
	DropDomains        []string `protobuf:"bytes,19,rep,name=dropDomains,proto3" json:"dropDomains,omitempty"`
	DomainDropPriority bool     `protobuf:"varint,20,opt,name=domainDropPriority,proto3" json:"domainDropPriority,omitempty"`
	// safe url normalizations happen by default. below is only for a few unsafe ones.
	// for list of safe normalizations: https://github.com/PuerkitoBio/purell/blob/master/purell.go#L59
	// remove index.php, etc,  fragments #section, +FlagsUsuallySafeGreedy from above link
	UnsafeNormalizeURL bool `protobuf:"varint,21,opt,name=unsafeNormalizeURL,proto3" json:"unsafeNormalizeURL,omitempty"`
	Login              bool `protobuf:"varint,22,opt,name=login,proto3" json:"login,omitempty"`
	// currently not possible, assumes false. uses chrome debugging protocol directly.
	LoginUsingSelenium bool   `protobuf:"varint,23,opt,name=loginUsingSelenium,proto3" json:"loginUsingSelenium,omitempty"`
	LoginUrl           string `protobuf:"bytes,24,opt,name=loginUrl,proto3" json:"loginUrl,omitempty"`
	// for username, password fields, other form data to send on post request
	LoginPayload []*KVP `protobuf:"bytes,25,rep,name=loginPayload,proto3" json:"loginPayload,omitempty"`
	// if there are hidden fields in the page that need to be scraped before login
	LoginParseFields bool `protobuf:"varint,26,opt,name=loginParseFields,proto3" json:"loginParseFields,omitempty"`
	// key is key of hidden fields to parse from form, value is the xpath of field to scrape.
	LoginParseXpath []*KVP `protobuf:"bytes,27,rep,name=loginParseXpath,proto3" json:"loginParseXpath,omitempty"`
	// to check if login succeeded, provide xpath as key, and expected value as value.
	// for example,  after login, xpath of top right corner,  and username as value.
	// if the xpath is not there of if there is no value match,  then we probably didn't login.
	LoginSuccessCheck *KVP `protobuf:"bytes,28,opt,name=loginSuccessCheck,proto3" json:"loginSuccessCheck,omitempty"`
	// checks login state after downloading each page, using check defined in 'loginSuccessCheck'
	CheckLoginAfterEachPage bool `protobuf:"varint,29,opt,name=checkLoginAfterEachPage,proto3" json:"checkLoginAfterEachPage,omitempty"`
	// javascript for login in chrome browser.
	LoginJS string `protobuf:"bytes,30,opt,name=loginJS,proto3" json:"loginJS,omitempty"`
	// whether to use chrome, location of chrome binary
	Chrome       bool   `protobuf:"varint,31,opt,name=chrome,proto3" json:"chrome,omitempty"`
	ChromeBinary string `protobuf:"bytes,32,opt,name=chromeBinary,proto3" json:"chromeBinary,omitempty"`
	DomLoadTime  int32  `protobuf:"varint,33,opt,name=domLoadTime,proto3" json:"domLoadTime,omitempty"`
	// check if this network interface is still active before every request.
	NetworkIface       string `protobuf:"bytes,34,opt,name=networkIface,proto3" json:"networkIface,omitempty"`
	CancelOnDisconnect bool   `protobuf:"varint,35,opt,name=cancelOnDisconnect,proto3" json:"cancelOnDisconnect,omitempty"`
	// if true,  sends a HEAD request first ensure content is text/html before sending GET request.
	CheckContent bool `protobuf:"varint,36,opt,name=checkContent,proto3" json:"checkContent,omitempty"`
	// if prefetch flag is true, downloads resources like img, css, png, svg, js associated with the actual page to mimic browser behaviour.
	Prefetch bool `protobuf:"varint,37,opt,name=prefetch,proto3" json:"prefetch,omitempty"`
	// pages matching anchor text regexp will be shipped back to the client.
	CallbackAnchorTextRegexp string `protobuf:"bytes,39,opt,name=callbackAnchorTextRegexp,proto3" json:"callbackAnchorTextRegexp,omitempty"`
	// If true ships the page at depth 0, else only pattern matched urls are shipped
	CallbackSeedUrl bool `protobuf:"varint,40,opt,name=callbackSeedUrl,proto3" json:"callbackSeedUrl,omitempty"`
	// disable loading images in chrome
	DisableImages bool `protobuf:"varint,41,opt,name=disableImages,proto3" json:"disableImages,omitempty"`
	// get page scroll count
	ScrollCount          int32    `protobuf:"varint,42,opt,name=scrollCount,proto3" json:"scrollCount,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *DomainOpt) Reset()         { *m = DomainOpt{} }
func (m *DomainOpt) String() string { return proto.CompactTextString(m) }
func (*DomainOpt) ProtoMessage()    {}
func (*DomainOpt) Descriptor() ([]byte, []int) {
	return fileDescriptor_f7828dc51d79295c, []int{3}
}

func (m *DomainOpt) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_DomainOpt.Unmarshal(m, b)
}
func (m *DomainOpt) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_DomainOpt.Marshal(b, m, deterministic)
}
func (m *DomainOpt) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DomainOpt.Merge(m, src)
}
func (m *DomainOpt) XXX_Size() int {
	return xxx_messageInfo_DomainOpt.Size(m)
}
func (m *DomainOpt) XXX_DiscardUnknown() {
	xxx_messageInfo_DomainOpt.DiscardUnknown(m)
}

var xxx_messageInfo_DomainOpt proto.InternalMessageInfo

func (m *DomainOpt) GetSeedUrl() string {
	if m != nil {
		return m.SeedUrl
	}
	return ""
}

func (m *DomainOpt) GetMinDelay() int32 {
	if m != nil {
		return m.MinDelay
	}
	return 0
}

func (m *DomainOpt) GetMaxDelay() int32 {
	if m != nil {
		return m.MaxDelay
	}
	return 0
}

func (m *DomainOpt) GetNoFollow() bool {
	if m != nil {
		return m.NoFollow
	}
	return false
}

func (m *DomainOpt) GetCallbackUrlRegexp() string {
	if m != nil {
		return m.CallbackUrlRegexp
	}
	return ""
}

func (m *DomainOpt) GetFollowUrlRegexp() string {
	if m != nil {
		return m.FollowUrlRegexp
	}
	return ""
}

func (m *DomainOpt) GetMaxConcurrentRequests() int32 {
	if m != nil {
		return m.MaxConcurrentRequests
	}
	return 0
}

func (m *DomainOpt) GetUseragent() string {
	if m != nil {
		return m.Useragent
	}
	return ""
}

func (m *DomainOpt) GetImpolite() bool {
	if m != nil {
		return m.Impolite
	}
	return false
}

func (m *DomainOpt) GetDepth() int32 {
	if m != nil {
		return m.Depth
	}
	return 0
}

func (m *DomainOpt) GetThreadsPerSite() int64 {
	if m != nil {
		return m.ThreadsPerSite
	}
	return 0
}

func (m *DomainOpt) GetCallbackXpathMatch() []*KVP {
	if m != nil {
		return m.CallbackXpathMatch
	}
	return nil
}

func (m *DomainOpt) GetCallbackXpathRegexp() []*KVP {
	if m != nil {
		return m.CallbackXpathRegexp
	}
	return nil
}

func (m *DomainOpt) GetMaxIdleTime() int64 {
	if m != nil {
		return m.MaxIdleTime
	}
	return 0
}

func (m *DomainOpt) GetFollowOtherDomains() bool {
	if m != nil {
		return m.FollowOtherDomains
	}
	return false
}

func (m *DomainOpt) GetKeepDomains() []string {
	if m != nil {
		return m.KeepDomains
	}
	return nil
}

func (m *DomainOpt) GetDropDomains() []string {
	if m != nil {
		return m.DropDomains
	}
	return nil
}

func (m *DomainOpt) GetDomainDropPriority() bool {
	if m != nil {
		return m.DomainDropPriority
	}
	return false
}

func (m *DomainOpt) GetUnsafeNormalizeURL() bool {
	if m != nil {
		return m.UnsafeNormalizeURL
	}
	return false
}

func (m *DomainOpt) GetLogin() bool {
	if m != nil {
		return m.Login
	}
	return false
}

func (m *DomainOpt) GetLoginUsingSelenium() bool {
	if m != nil {
		return m.LoginUsingSelenium
	}
	return false
}

func (m *DomainOpt) GetLoginUrl() string {
	if m != nil {
		return m.LoginUrl
	}
	return ""
}

func (m *DomainOpt) GetLoginPayload() []*KVP {
	if m != nil {
		return m.LoginPayload
	}
	return nil
}

func (m *DomainOpt) GetLoginParseFields() bool {
	if m != nil {
		return m.LoginParseFields
	}
	return false
}

func (m *DomainOpt) GetLoginParseXpath() []*KVP {
	if m != nil {
		return m.LoginParseXpath
	}
	return nil
}

func (m *DomainOpt) GetLoginSuccessCheck() *KVP {
	if m != nil {
		return m.LoginSuccessCheck
	}
	return nil
}

func (m *DomainOpt) GetCheckLoginAfterEachPage() bool {
	if m != nil {
		return m.CheckLoginAfterEachPage
	}
	return false
}

func (m *DomainOpt) GetLoginJS() string {
	if m != nil {
		return m.LoginJS
	}
	return ""
}

func (m *DomainOpt) GetChrome() bool {
	if m != nil {
		return m.Chrome
	}
	return false
}

func (m *DomainOpt) GetChromeBinary() string {
	if m != nil {
		return m.ChromeBinary
	}
	return ""
}

func (m *DomainOpt) GetDomLoadTime() int32 {
	if m != nil {
		return m.DomLoadTime
	}
	return 0
}

func (m *DomainOpt) GetNetworkIface() string {
	if m != nil {
		return m.NetworkIface
	}
	return ""
}

func (m *DomainOpt) GetCancelOnDisconnect() bool {
	if m != nil {
		return m.CancelOnDisconnect
	}
	return false
}

func (m *DomainOpt) GetCheckContent() bool {
	if m != nil {
		return m.CheckContent
	}
	return false
}

func (m *DomainOpt) GetPrefetch() bool {
	if m != nil {
		return m.Prefetch
	}
	return false
}

func (m *DomainOpt) GetCallbackAnchorTextRegexp() string {
	if m != nil {
		return m.CallbackAnchorTextRegexp
	}
	return ""
}

func (m *DomainOpt) GetCallbackSeedUrl() bool {
	if m != nil {
		return m.CallbackSeedUrl
	}
	return false
}

func (m *DomainOpt) GetDisableImages() bool {
	if m != nil {
		return m.DisableImages
	}
	return false
}

func (m *DomainOpt) GetScrollCount() int32 {
	if m != nil {
		return m.ScrollCount
	}
	return 0
}

type JobID struct {
	ID                   string   `protobuf:"bytes,1,opt,name=ID,json=iD,proto3" json:"ID,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *JobID) Reset()         { *m = JobID{} }
func (m *JobID) String() string { return proto.CompactTextString(m) }
func (*JobID) ProtoMessage()    {}
func (*JobID) Descriptor() ([]byte, []int) {
	return fileDescriptor_f7828dc51d79295c, []int{4}
}

func (m *JobID) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_JobID.Unmarshal(m, b)
}
func (m *JobID) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_JobID.Marshal(b, m, deterministic)
}
func (m *JobID) XXX_Merge(src proto.Message) {
	xxx_messageInfo_JobID.Merge(m, src)
}
func (m *JobID) XXX_Size() int {
	return xxx_messageInfo_JobID.Size(m)
}
func (m *JobID) XXX_DiscardUnknown() {
	xxx_messageInfo_JobID.DiscardUnknown(m)
}

var xxx_messageInfo_JobID proto.InternalMessageInfo

func (m *JobID) GetID() string {
	if m != nil {
		return m.ID
	}
	return ""
}

type PageRequest struct {
	JobID                *JobID      `protobuf:"bytes,1,opt,name=jobID,proto3" json:"jobID,omitempty"`
	Reqtype              PageReqType `protobuf:"varint,2,opt,name=reqtype,proto3,enum=protofiles.PageReqType" json:"reqtype,omitempty"`
	Url                  string      `protobuf:"bytes,3,opt,name=url,proto3" json:"url,omitempty"`
	Js                   string      `protobuf:"bytes,4,opt,name=js,proto3" json:"js,omitempty"`
	NoCallback           bool        `protobuf:"varint,5,opt,name=noCallback,proto3" json:"noCallback,omitempty"`
	MetaStr              string      `protobuf:"bytes,6,opt,name=metaStr,proto3" json:"metaStr,omitempty"`
	XXX_NoUnkeyedLiteral struct{}    `json:"-"`
	XXX_unrecognized     []byte      `json:"-"`
	XXX_sizecache        int32       `json:"-"`
}

func (m *PageRequest) Reset()         { *m = PageRequest{} }
func (m *PageRequest) String() string { return proto.CompactTextString(m) }
func (*PageRequest) ProtoMessage()    {}
func (*PageRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_f7828dc51d79295c, []int{5}
}

func (m *PageRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_PageRequest.Unmarshal(m, b)
}
func (m *PageRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_PageRequest.Marshal(b, m, deterministic)
}
func (m *PageRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_PageRequest.Merge(m, src)
}
func (m *PageRequest) XXX_Size() int {
	return xxx_messageInfo_PageRequest.Size(m)
}
func (m *PageRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_PageRequest.DiscardUnknown(m)
}

var xxx_messageInfo_PageRequest proto.InternalMessageInfo

func (m *PageRequest) GetJobID() *JobID {
	if m != nil {
		return m.JobID
	}
	return nil
}

func (m *PageRequest) GetReqtype() PageReqType {
	if m != nil {
		return m.Reqtype
	}
	return PageReqType_GET
}

func (m *PageRequest) GetUrl() string {
	if m != nil {
		return m.Url
	}
	return ""
}

func (m *PageRequest) GetJs() string {
	if m != nil {
		return m.Js
	}
	return ""
}

func (m *PageRequest) GetNoCallback() bool {
	if m != nil {
		return m.NoCallback
	}
	return false
}

func (m *PageRequest) GetMetaStr() string {
	if m != nil {
		return m.MetaStr
	}
	return ""
}

type PageHTML struct {
	Success              bool     `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	Error                string   `protobuf:"bytes,2,opt,name=error,proto3" json:"error,omitempty"`
	JobID                *JobID   `protobuf:"bytes,3,opt,name=jobID,proto3" json:"jobID,omitempty"`
	Url                  string   `protobuf:"bytes,4,opt,name=url,proto3" json:"url,omitempty"`
	Httpstatuscode       int32    `protobuf:"varint,5,opt,name=httpstatuscode,proto3" json:"httpstatuscode,omitempty"`
	Content              []byte   `protobuf:"bytes,6,opt,name=content,proto3" json:"content,omitempty"`
	MetaStr              string   `protobuf:"bytes,7,opt,name=metaStr,proto3" json:"metaStr,omitempty"`
	UrlDepth             int32    `protobuf:"varint,8,opt,name=urlDepth,proto3" json:"urlDepth,omitempty"`
	AnchorText           string   `protobuf:"bytes,9,opt,name=anchorText,proto3" json:"anchorText,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *PageHTML) Reset()         { *m = PageHTML{} }
func (m *PageHTML) String() string { return proto.CompactTextString(m) }
func (*PageHTML) ProtoMessage()    {}
func (*PageHTML) Descriptor() ([]byte, []int) {
	return fileDescriptor_f7828dc51d79295c, []int{6}
}

func (m *PageHTML) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_PageHTML.Unmarshal(m, b)
}
func (m *PageHTML) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_PageHTML.Marshal(b, m, deterministic)
}
func (m *PageHTML) XXX_Merge(src proto.Message) {
	xxx_messageInfo_PageHTML.Merge(m, src)
}
func (m *PageHTML) XXX_Size() int {
	return xxx_messageInfo_PageHTML.Size(m)
}
func (m *PageHTML) XXX_DiscardUnknown() {
	xxx_messageInfo_PageHTML.DiscardUnknown(m)
}

var xxx_messageInfo_PageHTML proto.InternalMessageInfo

func (m *PageHTML) GetSuccess() bool {
	if m != nil {
		return m.Success
	}
	return false
}

func (m *PageHTML) GetError() string {
	if m != nil {
		return m.Error
	}
	return ""
}

func (m *PageHTML) GetJobID() *JobID {
	if m != nil {
		return m.JobID
	}
	return nil
}

func (m *PageHTML) GetUrl() string {
	if m != nil {
		return m.Url
	}
	return ""
}

func (m *PageHTML) GetHttpstatuscode() int32 {
	if m != nil {
		return m.Httpstatuscode
	}
	return 0
}

func (m *PageHTML) GetContent() []byte {
	if m != nil {
		return m.Content
	}
	return nil
}

func (m *PageHTML) GetMetaStr() string {
	if m != nil {
		return m.MetaStr
	}
	return ""
}

func (m *PageHTML) GetUrlDepth() int32 {
	if m != nil {
		return m.UrlDepth
	}
	return 0
}

func (m *PageHTML) GetAnchorText() string {
	if m != nil {
		return m.AnchorText
	}
	return ""
}

type UrlList struct {
	Url                  []string `protobuf:"bytes,1,rep,name=url,proto3" json:"url,omitempty"`
	MetaStr              string   `protobuf:"bytes,2,opt,name=metaStr,proto3" json:"metaStr,omitempty"`
	UrlDepth             int32    `protobuf:"varint,3,opt,name=urlDepth,proto3" json:"urlDepth,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *UrlList) Reset()         { *m = UrlList{} }
func (m *UrlList) String() string { return proto.CompactTextString(m) }
func (*UrlList) ProtoMessage()    {}
func (*UrlList) Descriptor() ([]byte, []int) {
	return fileDescriptor_f7828dc51d79295c, []int{7}
}

func (m *UrlList) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_UrlList.Unmarshal(m, b)
}
func (m *UrlList) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_UrlList.Marshal(b, m, deterministic)
}
func (m *UrlList) XXX_Merge(src proto.Message) {
	xxx_messageInfo_UrlList.Merge(m, src)
}
func (m *UrlList) XXX_Size() int {
	return xxx_messageInfo_UrlList.Size(m)
}
func (m *UrlList) XXX_DiscardUnknown() {
	xxx_messageInfo_UrlList.DiscardUnknown(m)
}

var xxx_messageInfo_UrlList proto.InternalMessageInfo

func (m *UrlList) GetUrl() []string {
	if m != nil {
		return m.Url
	}
	return nil
}

func (m *UrlList) GetMetaStr() string {
	if m != nil {
		return m.MetaStr
	}
	return ""
}

func (m *UrlList) GetUrlDepth() int32 {
	if m != nil {
		return m.UrlDepth
	}
	return 0
}

func init() {
	proto.RegisterEnum("protofiles.PageReqType", PageReqType_name, PageReqType_value)
	proto.RegisterType((*WorkerID)(nil), "protofiles.WorkerID")
	proto.RegisterType((*Status)(nil), "protofiles.Status")
	proto.RegisterType((*KVP)(nil), "protofiles.KVP")
	proto.RegisterType((*DomainOpt)(nil), "protofiles.DomainOpt")
	proto.RegisterType((*JobID)(nil), "protofiles.JobID")
	proto.RegisterType((*PageRequest)(nil), "protofiles.PageRequest")
	proto.RegisterType((*PageHTML)(nil), "protofiles.PageHTML")
	proto.RegisterType((*UrlList)(nil), "protofiles.UrlList")
}

func init() { proto.RegisterFile("ideacrawler.proto", fileDescriptor_f7828dc51d79295c) }

var fileDescriptor_f7828dc51d79295c = []byte{
	// 1210 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x94, 0x56, 0xef, 0x76, 0x1a, 0xb7,
	0x12, 0x37, 0x10, 0x1b, 0x10, 0x8e, 0x8d, 0x95, 0x3f, 0xd6, 0x75, 0x72, 0x73, 0xb9, 0xdc, 0xdc,
	0x84, 0xe6, 0xb4, 0xa4, 0x75, 0xf2, 0x21, 0xfd, 0x93, 0xd3, 0x43, 0xc0, 0x49, 0x70, 0x48, 0x42,
	0x17, 0x48, 0xfb, 0x55, 0xde, 0x1d, 0x60, 0x83, 0x76, 0xb5, 0xd1, 0x8a, 0xc6, 0xe4, 0x1d, 0xfa,
	0x22, 0x7d, 0x8f, 0xbc, 0x57, 0x8f, 0x46, 0xbb, 0x78, 0x31, 0xe4, 0xf4, 0xf4, 0xd3, 0x6a, 0x7e,
	0xf3, 0xd3, 0x68, 0x46, 0x33, 0x3b, 0x23, 0x72, 0xe0, 0x7b, 0xc0, 0x5d, 0xc5, 0x3f, 0x0a, 0x50,
	0xcd, 0x48, 0x49, 0x2d, 0x29, 0xc1, 0xcf, 0xd8, 0x17, 0x10, 0x1f, 0xdd, 0x9a, 0x48, 0x39, 0x11,
	0xf0, 0x10, 0xa1, 0xb3, 0xf9, 0xf8, 0x21, 0x04, 0x91, 0x5e, 0x58, 0x62, 0xfd, 0x88, 0x94, 0x7e,
	0x95, 0x6a, 0x06, 0xaa, 0xdb, 0xa1, 0x7b, 0x24, 0xdf, 0xed, 0xb0, 0x5c, 0x2d, 0xd7, 0x28, 0x3b,
	0x79, 0xbf, 0x53, 0x7f, 0x42, 0x76, 0x06, 0x9a, 0xeb, 0x79, 0x4c, 0x19, 0x29, 0xc6, 0x73, 0xd7,
	0x85, 0x38, 0x46, 0x75, 0xc9, 0x49, 0x45, 0x7a, 0x9d, 0x6c, 0x83, 0x52, 0x52, 0xb1, 0x3c, 0x6e,
	0xb3, 0x42, 0xfd, 0x1b, 0x52, 0x78, 0xf5, 0xae, 0x4f, 0xab, 0xa4, 0x30, 0x83, 0x45, 0x62, 0xd1,
	0x2c, 0x0d, 0xfd, 0x77, 0x2e, 0xe6, 0x90, 0xd2, 0x51, 0xa8, 0xff, 0xb9, 0x4b, 0xca, 0x1d, 0x19,
	0x70, 0x3f, 0x7c, 0x1b, 0x69, 0x3c, 0x0c, 0xc0, 0x1b, 0x29, 0x91, 0xec, 0x4c, 0x45, 0x7a, 0x44,
	0x4a, 0x81, 0x1f, 0x76, 0x40, 0xf0, 0x05, 0x1a, 0xd8, 0x76, 0x96, 0x32, 0xea, 0xf8, 0xb9, 0xd5,
	0x15, 0x12, 0x5d, 0x22, 0x1b, 0x5d, 0x28, 0x9f, 0x4b, 0x21, 0xe4, 0x47, 0x76, 0x05, 0xfd, 0x5f,
	0xca, 0xf4, 0x6b, 0x72, 0xe0, 0x72, 0x21, 0xce, 0xb8, 0x3b, 0x1b, 0x29, 0xe1, 0xc0, 0x04, 0xce,
	0x23, 0xb6, 0x8d, 0xe7, 0xae, 0x2b, 0x68, 0x83, 0xec, 0x8f, 0x71, 0xdf, 0x05, 0x77, 0x07, 0xb9,
	0x97, 0x61, 0xfa, 0x98, 0xdc, 0x08, 0xf8, 0x79, 0x5b, 0x86, 0xee, 0x5c, 0x29, 0x08, 0xb5, 0x03,
	0x1f, 0xe6, 0x10, 0xeb, 0x98, 0x15, 0xd1, 0xb9, 0xcd, 0x4a, 0x7a, 0x9b, 0x94, 0xe7, 0x31, 0x28,
	0x3e, 0x81, 0x50, 0xb3, 0x12, 0x5a, 0xbe, 0x00, 0x4c, 0x1c, 0x7e, 0x10, 0x49, 0xe1, 0x6b, 0x60,
	0x65, 0x1b, 0x47, 0x2a, 0x9b, 0x9b, 0xf5, 0x20, 0xd2, 0x53, 0x46, 0xd0, 0xbe, 0x15, 0xe8, 0x3d,
	0xb2, 0x37, 0x9c, 0x2a, 0xe0, 0x5e, 0xdc, 0x07, 0x35, 0x30, 0xfb, 0x2a, 0xb5, 0x5c, 0xa3, 0xe0,
	0xec, 0xe9, 0x15, 0x94, 0xfe, 0x4c, 0x68, 0x1a, 0xec, 0x6f, 0x11, 0xd7, 0xd3, 0xd7, 0x5c, 0xbb,
	0x53, 0xb6, 0x57, 0x2b, 0x34, 0x2a, 0xc7, 0xfb, 0xcd, 0x8b, 0x62, 0x6a, 0xbe, 0x7a, 0xd7, 0x77,
	0x36, 0x50, 0x69, 0x8b, 0x5c, 0x5b, 0x41, 0x93, 0xcb, 0xd9, 0xdf, 0x6c, 0x61, 0x13, 0x97, 0xd6,
	0x48, 0x25, 0xe0, 0xe7, 0x5d, 0x4f, 0xc0, 0xd0, 0x0f, 0x80, 0x55, 0xd1, 0xd1, 0x2c, 0x44, 0x9b,
	0x84, 0xda, 0x6b, 0x7e, 0xab, 0xa7, 0xa0, 0x6c, 0xc5, 0xc4, 0xec, 0x00, 0x6f, 0x62, 0x83, 0xc6,
	0x58, 0x9c, 0x01, 0x44, 0x29, 0x91, 0xd6, 0x0a, 0x8d, 0xb2, 0x93, 0x85, 0x0c, 0xc3, 0x53, 0x72,
	0xc9, 0xb8, 0x66, 0x19, 0x19, 0xc8, 0x9c, 0xe9, 0xe1, 0xb2, 0xa3, 0x64, 0xd4, 0x57, 0xbe, 0x54,
	0xbe, 0x5e, 0xb0, 0xeb, 0xf6, 0xcc, 0x75, 0x8d, 0xe1, 0xcf, 0xc3, 0x98, 0x8f, 0xe1, 0x8d, 0x54,
	0x01, 0x17, 0xfe, 0x27, 0x18, 0x39, 0x3d, 0x76, 0xc3, 0xf2, 0xd7, 0x35, 0x26, 0x6f, 0x42, 0x4e,
	0xfc, 0x90, 0xdd, 0x44, 0x8a, 0x15, 0x8c, 0x15, 0x5c, 0x8c, 0x62, 0x3f, 0x9c, 0x0c, 0x40, 0x40,
	0xe8, 0xcf, 0x03, 0x76, 0x68, 0xad, 0xac, 0x6b, 0x4c, 0x65, 0x58, 0x54, 0x09, 0xc6, 0xb0, 0x6c,
	0x96, 0x32, 0x7d, 0x44, 0x76, 0x71, 0xdd, 0xe7, 0x0b, 0x21, 0xb9, 0xc7, 0xfe, 0xb5, 0x39, 0x27,
	0x2b, 0x24, 0xfa, 0x80, 0x54, 0x13, 0x59, 0xc5, 0xf0, 0xdc, 0x07, 0xe1, 0xc5, 0xec, 0x08, 0x8f,
	0x5f, 0xc3, 0xe9, 0xf7, 0x64, 0xff, 0x02, 0xc3, 0x8c, 0xb2, 0x5b, 0x9b, 0xcf, 0xb8, 0xcc, 0xa3,
	0x4f, 0xc9, 0x01, 0x42, 0x03, 0xdb, 0x4e, 0xda, 0x53, 0x70, 0x67, 0xec, 0x76, 0x2d, 0xb7, 0x69,
	0xf3, 0x3a, 0x93, 0x3e, 0x21, 0x87, 0xae, 0x59, 0xf4, 0x8c, 0xa6, 0x35, 0xd6, 0xa0, 0x4e, 0xb8,
	0x3b, 0xed, 0xf3, 0x09, 0xb0, 0x7f, 0xa3, 0xb3, 0x5f, 0x52, 0x9b, 0x26, 0x83, 0xe6, 0x4e, 0x07,
	0xec, 0x8e, 0x6d, 0x32, 0x89, 0x48, 0x6f, 0x92, 0x1d, 0x77, 0xaa, 0x64, 0x00, 0xec, 0x3f, 0x68,
	0x22, 0x91, 0x68, 0x9d, 0xec, 0xda, 0xd5, 0x33, 0x3f, 0xe4, 0x6a, 0xc1, 0x6a, 0xb8, 0x6d, 0x05,
	0xc3, 0x72, 0x92, 0x41, 0x4f, 0x72, 0x0f, 0x4b, 0xf8, 0xbf, 0xf8, 0x2b, 0x66, 0x21, 0x63, 0x25,
	0x04, 0xfd, 0x51, 0xaa, 0x59, 0x77, 0xcc, 0x5d, 0x60, 0x75, 0x6b, 0x25, 0x8b, 0x99, 0xe4, 0xbb,
	0x3c, 0x74, 0x41, 0xbc, 0x0d, 0x3b, 0x7e, 0xec, 0xca, 0x30, 0x04, 0x57, 0xb3, 0xff, 0xd9, 0xe4,
	0xaf, 0x6b, 0xac, 0x67, 0xe0, 0xce, 0xda, 0x32, 0xd4, 0xa6, 0x6f, 0xdc, 0x45, 0xe6, 0x0a, 0x66,
	0x0a, 0x24, 0x52, 0x30, 0x06, 0xf3, 0x5b, 0xff, 0xdf, 0xb6, 0x8e, 0x54, 0xa6, 0x3f, 0x10, 0x96,
	0xfe, 0x8f, 0xad, 0xd0, 0x9d, 0x4a, 0x35, 0x84, 0x73, 0x9d, 0xfc, 0xc0, 0xf7, 0xd1, 0xbf, 0x2f,
	0xea, 0x4d, 0x43, 0x4c, 0x75, 0x83, 0xa4, 0x69, 0x37, 0xd0, 0xfc, 0x65, 0x98, 0xde, 0x25, 0x57,
	0x3d, 0x3f, 0xe6, 0x67, 0x02, 0xba, 0x01, 0x9f, 0x40, 0xcc, 0xbe, 0x42, 0xde, 0x2a, 0x68, 0x6e,
	0x30, 0x76, 0x95, 0x14, 0xa2, 0x2d, 0xe7, 0xa1, 0x66, 0x0f, 0xec, 0x0d, 0x66, 0xa0, 0xfa, 0x21,
	0xd9, 0x3e, 0x95, 0x67, 0x1b, 0xc6, 0xd5, 0xe7, 0x1c, 0xa9, 0x98, 0xdc, 0x26, 0xcd, 0x94, 0xde,
	0x27, 0xdb, 0xef, 0x0d, 0x11, 0x29, 0x95, 0xe3, 0x83, 0x6c, 0x3d, 0xa1, 0x05, 0xc7, 0xea, 0xe9,
	0x77, 0xa4, 0xa8, 0xe0, 0x83, 0x5e, 0x44, 0x76, 0x2c, 0xed, 0x1d, 0x1f, 0x66, 0xa9, 0x89, 0xc9,
	0xe1, 0x22, 0x02, 0x27, 0xe5, 0x99, 0xc9, 0x36, 0x57, 0x02, 0x07, 0x4d, 0xd9, 0x31, 0x4b, 0xe3,
	0xcd, 0xfb, 0x18, 0xa7, 0x4b, 0xd9, 0xc9, 0xbf, 0x8f, 0xe9, 0x1d, 0x42, 0x42, 0xd9, 0x4e, 0xee,
	0x00, 0x07, 0x4a, 0xc9, 0xc9, 0x20, 0xa6, 0x00, 0x03, 0xd0, 0x7c, 0xa0, 0x55, 0x32, 0x41, 0x52,
	0xb1, 0xfe, 0x47, 0x9e, 0x94, 0xcc, 0xa1, 0x2f, 0x87, 0xaf, 0x7b, 0xff, 0x74, 0xf2, 0x5e, 0x04,
	0x5d, 0xf8, 0x9b, 0xa0, 0x93, 0x08, 0xae, 0x5c, 0x44, 0x70, 0x8f, 0xec, 0x4d, 0xb5, 0x8e, 0x62,
	0x1c, 0xf9, 0xae, 0xf4, 0x00, 0xbd, 0xde, 0x76, 0x2e, 0xa1, 0xc6, 0x25, 0x37, 0xa9, 0x34, 0xe3,
	0xf9, 0xae, 0x93, 0x8a, 0xd9, 0x98, 0x8a, 0x2b, 0x31, 0x99, 0xf2, 0x9b, 0x2b, 0xd1, 0xc1, 0x01,
	0x55, 0xb2, 0xd3, 0x39, 0x95, 0xcd, 0x4d, 0xf1, 0x65, 0x59, 0xe1, 0x5c, 0x2b, 0x3b, 0x19, 0xa4,
	0xfe, 0x0b, 0x29, 0x8e, 0x94, 0xe8, 0xf9, 0xb1, 0x4e, 0x9d, 0xce, 0x61, 0x9b, 0x46, 0xa7, 0x33,
	0x47, 0xe6, 0xbf, 0x7c, 0x64, 0x61, 0xf5, 0xc8, 0x07, 0x3f, 0x2d, 0x2b, 0xc5, 0xa4, 0x95, 0x16,
	0x49, 0xe1, 0xc5, 0xc9, 0xb0, 0xba, 0x45, 0x4b, 0xe4, 0xca, 0xcb, 0x93, 0x56, 0xa7, 0x9a, 0xa3,
	0x57, 0x49, 0xf9, 0xd9, 0xa8, 0xdb, 0x1b, 0x76, 0xdf, 0x9c, 0x0e, 0xaa, 0x79, 0x5a, 0x21, 0xc5,
	0xd3, 0x41, 0xdb, 0xe9, 0xf6, 0x87, 0xd5, 0xc2, 0xf1, 0xe7, 0x3c, 0xa9, 0x74, 0x3d, 0xe0, 0x6d,
	0xfb, 0xe4, 0xa2, 0x27, 0x84, 0xb6, 0x3c, 0xcf, 0x0e, 0x8c, 0x56, 0xe8, 0x19, 0x4f, 0x21, 0xa4,
	0x37, 0xb2, 0x57, 0xbf, 0x7c, 0xdd, 0x1c, 0x5d, 0xbf, 0x5c, 0x5b, 0x26, 0xcd, 0xf5, 0xad, 0x6f,
	0x73, 0xf4, 0x47, 0x52, 0x6a, 0x79, 0x5e, 0x1f, 0x7f, 0x83, 0x4d, 0x15, 0x68, 0x8a, 0xfa, 0x88,
	0x66, 0x15, 0xf6, 0x75, 0x56, 0xdf, 0x6a, 0xe4, 0xe8, 0x63, 0x52, 0x6e, 0x63, 0x67, 0x38, 0x95,
	0x67, 0x74, 0x3d, 0xeb, 0x9b, 0xf7, 0xd1, 0xa7, 0x64, 0xff, 0x05, 0xe8, 0x56, 0xc8, 0xc5, 0xe2,
	0x13, 0x78, 0x23, 0xa7, 0x17, 0x6f, 0xda, 0x7b, 0x2d, 0x0b, 0x25, 0xa9, 0x40, 0x8f, 0x9f, 0x92,
	0xca, 0x0b, 0xd0, 0xcb, 0xf7, 0xe3, 0xcd, 0xa6, 0x7d, 0x69, 0x36, 0xd3, 0x97, 0x66, 0xf3, 0xc4,
	0xbc, 0x34, 0x57, 0x43, 0x4e, 0xd9, 0xf5, 0xad, 0xb3, 0x1d, 0x84, 0x1f, 0xfd, 0x15, 0x00, 0x00,
	0xff, 0xff, 0xfa, 0x96, 0x12, 0x6b, 0xc0, 0x0a, 0x00, 0x00,
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// IdeaCrawlerClient is the client API for IdeaCrawler service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type IdeaCrawlerClient interface {
	AddDomainAndListen(ctx context.Context, in *DomainOpt, opts ...grpc.CallOption) (IdeaCrawler_AddDomainAndListenClient, error)
	AddPages(ctx context.Context, opts ...grpc.CallOption) (IdeaCrawler_AddPagesClient, error)
	CancelJob(ctx context.Context, in *JobID, opts ...grpc.CallOption) (*Status, error)
	GetAnalyzedURLs(ctx context.Context, in *JobID, opts ...grpc.CallOption) (IdeaCrawler_GetAnalyzedURLsClient, error)
	GetWorkerID(ctx context.Context, in *empty.Empty, opts ...grpc.CallOption) (*WorkerID, error)
}

type ideaCrawlerClient struct {
	cc *grpc.ClientConn
}

func NewIdeaCrawlerClient(cc *grpc.ClientConn) IdeaCrawlerClient {
	return &ideaCrawlerClient{cc}
}

func (c *ideaCrawlerClient) AddDomainAndListen(ctx context.Context, in *DomainOpt, opts ...grpc.CallOption) (IdeaCrawler_AddDomainAndListenClient, error) {
	stream, err := c.cc.NewStream(ctx, &_IdeaCrawler_serviceDesc.Streams[0], "/protofiles.IdeaCrawler/AddDomainAndListen", opts...)
	if err != nil {
		return nil, err
	}
	x := &ideaCrawlerAddDomainAndListenClient{stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type IdeaCrawler_AddDomainAndListenClient interface {
	Recv() (*PageHTML, error)
	grpc.ClientStream
}

type ideaCrawlerAddDomainAndListenClient struct {
	grpc.ClientStream
}

func (x *ideaCrawlerAddDomainAndListenClient) Recv() (*PageHTML, error) {
	m := new(PageHTML)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

func (c *ideaCrawlerClient) AddPages(ctx context.Context, opts ...grpc.CallOption) (IdeaCrawler_AddPagesClient, error) {
	stream, err := c.cc.NewStream(ctx, &_IdeaCrawler_serviceDesc.Streams[1], "/protofiles.IdeaCrawler/AddPages", opts...)
	if err != nil {
		return nil, err
	}
	x := &ideaCrawlerAddPagesClient{stream}
	return x, nil
}

type IdeaCrawler_AddPagesClient interface {
	Send(*PageRequest) error
	CloseAndRecv() (*Status, error)
	grpc.ClientStream
}

type ideaCrawlerAddPagesClient struct {
	grpc.ClientStream
}

func (x *ideaCrawlerAddPagesClient) Send(m *PageRequest) error {
	return x.ClientStream.SendMsg(m)
}

func (x *ideaCrawlerAddPagesClient) CloseAndRecv() (*Status, error) {
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	m := new(Status)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

func (c *ideaCrawlerClient) CancelJob(ctx context.Context, in *JobID, opts ...grpc.CallOption) (*Status, error) {
	out := new(Status)
	err := c.cc.Invoke(ctx, "/protofiles.IdeaCrawler/CancelJob", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *ideaCrawlerClient) GetAnalyzedURLs(ctx context.Context, in *JobID, opts ...grpc.CallOption) (IdeaCrawler_GetAnalyzedURLsClient, error) {
	stream, err := c.cc.NewStream(ctx, &_IdeaCrawler_serviceDesc.Streams[2], "/protofiles.IdeaCrawler/GetAnalyzedURLs", opts...)
	if err != nil {
		return nil, err
	}
	x := &ideaCrawlerGetAnalyzedURLsClient{stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type IdeaCrawler_GetAnalyzedURLsClient interface {
	Recv() (*UrlList, error)
	grpc.ClientStream
}

type ideaCrawlerGetAnalyzedURLsClient struct {
	grpc.ClientStream
}

func (x *ideaCrawlerGetAnalyzedURLsClient) Recv() (*UrlList, error) {
	m := new(UrlList)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

func (c *ideaCrawlerClient) GetWorkerID(ctx context.Context, in *empty.Empty, opts ...grpc.CallOption) (*WorkerID, error) {
	out := new(WorkerID)
	err := c.cc.Invoke(ctx, "/protofiles.IdeaCrawler/GetWorkerID", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// IdeaCrawlerServer is the server API for IdeaCrawler service.
type IdeaCrawlerServer interface {
	AddDomainAndListen(*DomainOpt, IdeaCrawler_AddDomainAndListenServer) error
	AddPages(IdeaCrawler_AddPagesServer) error
	CancelJob(context.Context, *JobID) (*Status, error)
	GetAnalyzedURLs(*JobID, IdeaCrawler_GetAnalyzedURLsServer) error
	GetWorkerID(context.Context, *empty.Empty) (*WorkerID, error)
}

func RegisterIdeaCrawlerServer(s *grpc.Server, srv IdeaCrawlerServer) {
	s.RegisterService(&_IdeaCrawler_serviceDesc, srv)
}

func _IdeaCrawler_AddDomainAndListen_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(DomainOpt)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(IdeaCrawlerServer).AddDomainAndListen(m, &ideaCrawlerAddDomainAndListenServer{stream})
}

type IdeaCrawler_AddDomainAndListenServer interface {
	Send(*PageHTML) error
	grpc.ServerStream
}

type ideaCrawlerAddDomainAndListenServer struct {
	grpc.ServerStream
}

func (x *ideaCrawlerAddDomainAndListenServer) Send(m *PageHTML) error {
	return x.ServerStream.SendMsg(m)
}

func _IdeaCrawler_AddPages_Handler(srv interface{}, stream grpc.ServerStream) error {
	return srv.(IdeaCrawlerServer).AddPages(&ideaCrawlerAddPagesServer{stream})
}

type IdeaCrawler_AddPagesServer interface {
	SendAndClose(*Status) error
	Recv() (*PageRequest, error)
	grpc.ServerStream
}

type ideaCrawlerAddPagesServer struct {
	grpc.ServerStream
}

func (x *ideaCrawlerAddPagesServer) SendAndClose(m *Status) error {
	return x.ServerStream.SendMsg(m)
}

func (x *ideaCrawlerAddPagesServer) Recv() (*PageRequest, error) {
	m := new(PageRequest)
	if err := x.ServerStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

func _IdeaCrawler_CancelJob_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(JobID)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(IdeaCrawlerServer).CancelJob(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/protofiles.IdeaCrawler/CancelJob",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(IdeaCrawlerServer).CancelJob(ctx, req.(*JobID))
	}
	return interceptor(ctx, in, info, handler)
}

func _IdeaCrawler_GetAnalyzedURLs_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(JobID)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(IdeaCrawlerServer).GetAnalyzedURLs(m, &ideaCrawlerGetAnalyzedURLsServer{stream})
}

type IdeaCrawler_GetAnalyzedURLsServer interface {
	Send(*UrlList) error
	grpc.ServerStream
}

type ideaCrawlerGetAnalyzedURLsServer struct {
	grpc.ServerStream
}

func (x *ideaCrawlerGetAnalyzedURLsServer) Send(m *UrlList) error {
	return x.ServerStream.SendMsg(m)
}

func _IdeaCrawler_GetWorkerID_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(empty.Empty)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(IdeaCrawlerServer).GetWorkerID(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/protofiles.IdeaCrawler/GetWorkerID",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(IdeaCrawlerServer).GetWorkerID(ctx, req.(*empty.Empty))
	}
	return interceptor(ctx, in, info, handler)
}

var _IdeaCrawler_serviceDesc = grpc.ServiceDesc{
	ServiceName: "protofiles.IdeaCrawler",
	HandlerType: (*IdeaCrawlerServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "CancelJob",
			Handler:    _IdeaCrawler_CancelJob_Handler,
		},
		{
			MethodName: "GetWorkerID",
			Handler:    _IdeaCrawler_GetWorkerID_Handler,
		},
	},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "AddDomainAndListen",
			Handler:       _IdeaCrawler_AddDomainAndListen_Handler,
			ServerStreams: true,
		},
		{
			StreamName:    "AddPages",
			Handler:       _IdeaCrawler_AddPages_Handler,
			ClientStreams: true,
		},
		{
			StreamName:    "GetAnalyzedURLs",
			Handler:       _IdeaCrawler_GetAnalyzedURLs_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "ideacrawler.proto",
}
